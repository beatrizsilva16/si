{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Exercício 8: Adiciona o método randomized_search_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O método randomized_search_cv implementa uma estratégia de otimização de parâmetros de usando Nº\n",
    "combinações aleatórias. O randomized_search_cv avalia apenas um conjunto aleatório de parâmetros\n",
    "retirados de uma distribuição ou conjunto de valores possíveis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8.2) Valida a tua implementação seguindo o protocolo:\n",
    "1. Usa o dataset breast-bin.csv\n",
    "2. Usa o sklearn.preprocessing.StandardScaler para standardizar os dataset.\n",
    "breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n",
    "3. Cria o modelo LogisticRegression\n",
    "4. Realiza uma procura aleatória com as seguintes distribuições de parâmetros:\n",
    "• l2_penalty: distribuição entre 1 e 10 com 10 intervalos iguais (e.g., np.linspace(1, 10, 10))\n",
    "• alpha: distribuição entre 0.001 e 0.0001 com 100 intervalos iguais (e.g., np.linspace(0.001, 0.0001, 100))\n",
    "• max_iter: distribuição entre 1000 e 2000 com 200 intervalos iguais (e.g., np.linspace(1000, 2000, 200))\n",
    "5. Podes usar n_iter de 10 e 3 folds para o cross_validate.\n",
    "6. Quais os scores obtidos?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from si.io_folder.csv_file import read_csv\n",
    "from si.model_selection.cross_validate import cross_validate\n",
    "from si.linear_model.logistic_regression import LogisticRegression\n",
    "from si.model_selection.randomized_search_cv import randomized_search_cv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# (1)\n",
    "breast = read_csv('C:/Users/beatr/Mestrado/2ºano/si/datasets/breast-bin.csv', sep=',', features=True, label=True)\n",
    "\n",
    "#(2)\n",
    "breast.X = StandardScaler().fit_transform(breast.X)\n",
    "\n",
    "#(3)\n",
    "lr = LogisticRegression(l2_penalty= 1, alpha= 0.001, max_iter=2000)\n",
    "\n",
    "# (4) Performs a cross validation with 5 folds\n",
    "scores = cross_validate(lr, breast, cv=5)\n",
    "\n",
    "# (5) What is the score obtained?\n",
    "print(f\"The cross validation scores: {score}\")\n",
    "\n",
    "\n",
    "# - Exercise 2: Test the grid_search using the breast-bin.csv dataset\n",
    "\n",
    "# (1) Read csv file - breast-bin.csv\n",
    "breast_file = \"../datasets/breast-bin.csv\"\n",
    "breast = read_csv(filename=breast_file, sep=\",\", features=True, label=True)\n",
    "\n",
    "# (2) Standardize features by removing the mean and scaling to unit variance.\n",
    "breast.X = StandardScaler().fit_transform(breast.X)\n",
    "\n",
    "# (3) Create Logistic Regression model\n",
    "lr2 = LogisticRegression(l2_penalty= 1, alpha= 0.001, max_iter=2000)\n",
    "\n",
    "# (4) Perform a grid search with the following parameters\n",
    "lr2_param = {'l2_penalty': [1, 10], 'alpha': [0.001, 0.0001], 'max_iter': [1000, 2000]}\n",
    "\n",
    "# (5) cross validate the model with 3 folds\n",
    "scores = cross_validate(lr2_param, breast, cv=3)\n",
    "\n",
    "# (6) What is the score obtained?\n",
    "print(f\"The scores: {scores}\")\n",
    "\n",
    "# - Exercise 8: Test the randomized_search_cv using the breast-bin.csv dataset\n",
    "\n",
    "# (1) Read csv file - breast-bin.csv\n",
    "breast_file = \"../datasets/breast-bin.csv\"\n",
    "breast = read_csv(filename=breast_file, sep=\",\", features=True, label=True)\n",
    "\n",
    "# (2) Standardize features by removing the mean and scaling to unit variance.\n",
    "breast.X = StandardScaler().fit_transform(breast.X)\n",
    "\n",
    "# (3) Create Logistic Regression model\n",
    "lr3 = LogisticRegression(l2_penalty= 1, alpha= 0.001, max_iter=2000)\n",
    "\n",
    "# (4) Perform a randomized search with the following parameters\n",
    "lr3_param = {'l2_penalty': np.linspace(1, 10, 10), 'alpha': np.linspace(0.001, 0.0001, 100),\n",
    "             'max_iter': np.linspace(1000, 2000, 200)}\n",
    "\n",
    "# (5.1) cross validate the model with 3 folds\n",
    "scores_3 = randomized_search_cv(lr3, breast, lr3_param, cv=3)\n",
    "\n",
    "# (5.2) cross validate the model with 10 folds\n",
    "scores_10 = randomized_search_cv(lr3, breast, lr3_param, cv=10)\n",
    "\n",
    "# (6) What is the score obtained?\n",
    "print(f\"The scores with 3 folds: {scores_3}\")\n",
    "print(f\"The scores with 10 folds: {scores_10}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}